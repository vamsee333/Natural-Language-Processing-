{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the libraries related to NLP\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample customer reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = pd.read_csv(\"main_customer_reviews.csv\", encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>experience_with_device</th>\n",
       "      <th>user_interface</th>\n",
       "      <th>overall_experience</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>good experience and I liked it.</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>enjoyed it a lot. No isses with the device</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>easy to monitor the results</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>not satisfied</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>hard to control</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID                      experience_with_device  user_interface  \\\n",
       "0        1001             good experience and I liked it.               8   \n",
       "1        1002  enjoyed it a lot. No isses with the device               9   \n",
       "2        1003                 easy to monitor the results               9   \n",
       "3        1004                               not satisfied               3   \n",
       "4        1004                             hard to control               3   \n",
       "\n",
       "   overall_experience     label  \n",
       "0                   8  positive  \n",
       "1                   8  positive  \n",
       "2                  10  positive  \n",
       "3                   5  negative  \n",
       "4                   6  negative  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       good experience and I liked it.\n",
       "1            enjoyed it a lot. No isses with the device\n",
       "2                           easy to monitor the results\n",
       "3                                         not satisfied\n",
       "4                                       hard to control\n",
       "                            ...                        \n",
       "86    This product is really amazing. And I'm buying...\n",
       "87    I have been using this product for quite a whi...\n",
       "88    Its quite complicated to use and takes a lot o...\n",
       "89    I didn’t expect the product to be this accurat...\n",
       "90    I was skeptical about buying this product but ...\n",
       "Name: experience_with_device, Length: 91, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data[\"experience_with_device\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets work on the raw text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps= nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the above method performs all cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join(word for word in text if word not in string.punctuation)\n",
    "    tokens = re.split(\"\\W+\", text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data[\"cleaned_text\"]= review_data[\"experience_with_device\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>experience_with_device</th>\n",
       "      <th>user_interface</th>\n",
       "      <th>overall_experience</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>good experience and I liked it.</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>positive</td>\n",
       "      <td>[good, experi, I, like]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>enjoyed it a lot. No isses with the device</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>positive</td>\n",
       "      <td>[enjoy, lot, No, iss, devic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>easy to monitor the results</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>positive</td>\n",
       "      <td>[easi, monitor, result]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>not satisfied</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>[satisfi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>hard to control</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>[hard, control]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID                      experience_with_device  user_interface  \\\n",
       "0        1001             good experience and I liked it.               8   \n",
       "1        1002  enjoyed it a lot. No isses with the device               9   \n",
       "2        1003                 easy to monitor the results               9   \n",
       "3        1004                               not satisfied               3   \n",
       "4        1004                             hard to control               3   \n",
       "\n",
       "   overall_experience     label                  cleaned_text  \n",
       "0                   8  positive       [good, experi, I, like]  \n",
       "1                   8  positive  [enjoy, lot, No, iss, devic]  \n",
       "2                  10  positive       [easi, monitor, result]  \n",
       "3                   5  negative                     [satisfi]  \n",
       "4                   6  negative               [hard, control]  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tasks to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature extraction and add new features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. length of the text\n",
    "2. punctuations\n",
    "3. capital letters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2. perform lemmatization by changing the clean_text method or implement a new method with lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### before vectorizing, lets split the data into train, test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(review_data[[\"experience_with_device\",\"user_interface\",\"overall_experience\"]], review_data[\"label\"] , test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count vectorization\n",
    "cv_model = CountVectorizer(analyzer=clean_text)\n",
    "cv_fit_model = cv_model.fit(X_train[\"experience_with_device\"])\n",
    "count_train = cv_fit_model.transform(X_train[\"experience_with_device\"])\n",
    "count_test = cv_fit_model.transform(X_test[\"experience_with_device\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in the same way, build tf-idf vectorizer\n",
    "tfidf_model= TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_fit_model = tfidf_model.fit(X_train[\"experience_with_device\"])\n",
    "tfidf_train = tfidf_fit_model.transform(X_train[\"experience_with_device\"])\n",
    "tfidf_test = tfidf_fit_model.transform(X_test[\"experience_with_device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now combine the vectorized data with the existing features for the train and test data\n",
    "\n",
    "X_train_vect = pd.concat([X_train[[\"user_interface\",\"overall_experience\"]].reset_index(drop=True),pd.DataFrame(tfidf_train.toarray())], axis=1 )\n",
    "X_test_vect = pd.concat([X_test[[\"user_interface\",\"overall_experience\"]].reset_index(drop=True),pd.DataFrame(tfidf_test.toarray())], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_interface</th>\n",
       "      <th>overall_experience</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.470235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.323266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_interface  overall_experience         0    1         2    3         4  \\\n",
       "0              10                  10  0.000000  0.0  0.000000  0.0  0.537911   \n",
       "1               3                   5  0.000000  0.0  0.295423  0.0  0.000000   \n",
       "2               9                   8  0.000000  0.0  0.000000  0.0  0.000000   \n",
       "3               5                   7  0.470235  0.0  0.000000  0.0  0.000000   \n",
       "4               7                   7  0.323266  0.0  0.000000  0.0  0.000000   \n",
       "\n",
       "     5         6    7  ...  175  176  177  178  179  180  181  182  183  \\\n",
       "0  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.503253  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.000000  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       184  \n",
       "0  0.00000  \n",
       "1  0.00000  \n",
       "2  0.00000  \n",
       "3  0.72353  \n",
       "4  0.00000  \n",
       "\n",
       "[5 rows x 187 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. perform grid search CV for the hyperparameter tuning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 count vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### It builds models with various values to the hyper parameters as input\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv_model = CountVectorizer(analyzer=clean_text)\n",
    "cv_model_vect = cv_model.fit_transform(review_data[\"experience_with_device\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_vect_df = pd.DataFrame(cv_model_vect.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_vect_df.columns =cv_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now combine the features with the vector dataframe\n",
    "\n",
    "cv_dataframe = pd.concat([review_data[[\"user_interface\",\"overall_experience\"]].reset_index(drop=True), cv_vect_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_interface</th>\n",
       "      <th>overall_experience</th>\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>I</th>\n",
       "      <th>Im</th>\n",
       "      <th>It</th>\n",
       "      <th>NO</th>\n",
       "      <th>No</th>\n",
       "      <th>abl</th>\n",
       "      <th>...</th>\n",
       "      <th>wast</th>\n",
       "      <th>way</th>\n",
       "      <th>weak</th>\n",
       "      <th>week</th>\n",
       "      <th>well</th>\n",
       "      <th>wish</th>\n",
       "      <th>work</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_interface  overall_experience     10  I  Im  It  NO  No  abl  ...  \\\n",
       "0               8                   8  0   0  1   0   0   0   0    0  ...   \n",
       "1               9                   8  0   0  0   0   0   0   1    0  ...   \n",
       "\n",
       "   wast  way  weak  week  well  wish  work  worst  worth  wrong  \n",
       "0     0    0     0     0     0     0     0      0      0      0  \n",
       "1     0    0     0     0     0     0     0      0      0      0  \n",
       "\n",
       "[2 rows x 210 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_traincv, X_testcv, Y_traincv, Y_testcv = train_test_split(cv_dataframe,review_data[\"label\"], test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_cv_model = RandomForestClassifier()\n",
    "params = {\"n_estimators\":[10,30,50,100,150], \"max_depth\":[None, 20, 60, 120, 200]}\n",
    "Grid_cv_model = GridSearchCV(rf_cv_model, params, cv= 5, n_jobs=-1)\n",
    "\n",
    "Grid_cv_model_fit = Grid_cv_model.fit(X_traincv, Y_traincv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = pd.DataFrame(Grid_cv_model_fit.cv_results_).sort_values(\"mean_test_score\", ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1.to_csv('gridsearch_count_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = Grid_cv_model_fit.predict(X_testcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GB_cv_model = GradientBoostingClassifier()\n",
    "params = {\"n_estimators\":[10,30,50,100,150], \"max_depth\":[None, 20, 60, 120, 200]}\n",
    "Grid_cv_model = GridSearchCV(GB_cv_model, params, cv= 5, n_jobs=-1)\n",
    "\n",
    "Grid_cv_model_fit = Grid_cv_model.fit(X_traincv, Y_traincv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = pd.DataFrame(Grid_cv_model_fit.cv_results_).sort_values(\"mean_test_score\", ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1.to_csv('GB_gridsearch_count_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2  TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "\n",
    "tfidf_model = CountVectorizer(analyzer=clean_text)\n",
    "tfidf_model_vect = tfidf_model.fit_transform(review_data[\"experience_with_device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_df = pd.DataFrame(tfidf_model_vect.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_df.columns =tfidf_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now combine the features with the vector dataframe\n",
    "\n",
    "tfidf_dataframe = pd.concat([review_data[[\"user_interface\",\"overall_experience\"]].reset_index(drop=True), tfidf_vect_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_interface</th>\n",
       "      <th>overall_experience</th>\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>I</th>\n",
       "      <th>Im</th>\n",
       "      <th>It</th>\n",
       "      <th>NO</th>\n",
       "      <th>No</th>\n",
       "      <th>abl</th>\n",
       "      <th>...</th>\n",
       "      <th>wast</th>\n",
       "      <th>way</th>\n",
       "      <th>weak</th>\n",
       "      <th>week</th>\n",
       "      <th>well</th>\n",
       "      <th>wish</th>\n",
       "      <th>work</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_interface  overall_experience     10  I  Im  It  NO  No  abl  ...  \\\n",
       "0               8                   8  0   0  1   0   0   0   0    0  ...   \n",
       "1               9                   8  0   0  0   0   0   0   1    0  ...   \n",
       "\n",
       "   wast  way  weak  week  well  wish  work  worst  worth  wrong  \n",
       "0     0    0     0     0     0     0     0      0      0      0  \n",
       "1     0    0     0     0     0     0     0      0      0      0  \n",
       "\n",
       "[2 rows x 210 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_traincv, X_testcv, Y_traincv, Y_testcv = train_test_split(tfidf_dataframe,review_data[\"label\"], test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_tfidf_model = RandomForestClassifier()\n",
    "params = {\"n_estimators\":[10,30,50,100,150], \"max_depth\":[None, 20, 60, 120, 200]}\n",
    "Grid_tfidf_model = GridSearchCV(rf_tfidf_model, params, cv= 5, n_jobs=-1)\n",
    "\n",
    "Grid_tfidf_model_fit = Grid_tfidf_model.fit(X_traincv, Y_traincv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = pd.DataFrame(Grid_tfidf_model_fit.cv_results_).sort_values(\"mean_test_score\", ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.to_csv('gridsearch_tfidf_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GB_tfidf_model = GradientBoostingClassifier()\n",
    "params = {\"n_estimators\":[10,30,50,100,150], \"max_depth\":[None, 20, 60, 120, 200]}\n",
    "Grid_tfidf_model = GridSearchCV(GB_tfidf_model, params, cv= 5, n_jobs=-1)\n",
    "\n",
    "Grid_tfidf_model_fit = Grid_tfidf_model.fit(X_traincv, Y_traincv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = pd.DataFrame(Grid_tfidf_model_fit.cv_results_).sort_values(\"mean_test_score\", ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.to_csv('GB_gridsearch_tfidf_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Final Random Forest Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit-time 0.0, pred-time 0.007, precision 1.0, recall 0.89\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=30, max_depth=None)\n",
    "fit_time = time.time()\n",
    "rf_model.fit(X_train_vect, Y_train)\n",
    "fit_end_time= time.time()\n",
    "total = fit_end_time - fit_end_time\n",
    "\n",
    "pred_time = time.time()\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "end_time = time.time()\n",
    "pred_total = end_time - pred_time\n",
    "\n",
    "precision,recall,fscore,support = precision_recall_fscore_support(Y_test, y_pred, pos_label=\"negative\", average =\"binary\")\n",
    "\n",
    "print(\"fit-time {}, pred-time {}, precision {}, recall {}\".format(round(total,3), round(pred_total,3), round(precision,3), round(recall,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Final Gradiant Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit-time 0.0, pred-time 0.003, precision 1.0, recall 0.67\n"
     ]
    }
   ],
   "source": [
    "grad_model = GradientBoostingClassifier(max_depth= None, n_estimators=10 )\n",
    "fit_time = time.time()\n",
    "grad_model.fit(X_train_vect, Y_train)\n",
    "fit_end_time= time.time()\n",
    "total = fit_end_time - fit_end_time\n",
    "\n",
    "pred_time = time.time()\n",
    "y_pred = grad_model.predict(X_test_vect)\n",
    "end_time = time.time()\n",
    "pred_total = end_time - pred_time\n",
    "\n",
    "precision,recall,fscore,support = precision_recall_fscore_support(Y_test, y_pred, pos_label=\"negative\", average =\"binary\")\n",
    "\n",
    "print(\"fit-time {}, pred-time {}, precision {}, recall {}\".format(round(total,3), round(pred_total,3), round(precision,3), round(recall,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch CV for the hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':[10,30,50,100], 'max_depth':[None,10,50,70,100]}\n",
    "rf_model_2 = RandomForestClassifier()\n",
    "grid_rf_model = GridSearchCV(rf_model_2,params,cv=5, n_jobs=-1)\n",
    "\n",
    "grid_rf_fit = grid_rf_model.fit(X_train_vect, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029426</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.004928</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 10}</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.924167</td>\n",
       "      <td>0.061090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.030662</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'n_estimators': 10}</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.060576</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029636</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 10}</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.027573</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 10}</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.885833</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.249890</td>\n",
       "      <td>0.011335</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 50, 'n_estimators': 100}</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.885833</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.029426      0.001356         0.004928        0.004764   \n",
       "16       0.030662      0.002118         0.004399        0.001427   \n",
       "4        0.029636      0.003866         0.005866        0.000437   \n",
       "8        0.027573      0.004715         0.008021        0.002833   \n",
       "11       0.249890      0.011335         0.018764        0.003670   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "0             None                 10   \n",
       "16             100                 10   \n",
       "4               10                 10   \n",
       "8               50                 10   \n",
       "11              50                100   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0   {'max_depth': None, 'n_estimators': 10}             0.9375   \n",
       "16   {'max_depth': 100, 'n_estimators': 10}             0.9375   \n",
       "4     {'max_depth': 10, 'n_estimators': 10}             0.8750   \n",
       "8     {'max_depth': 50, 'n_estimators': 10}             0.8750   \n",
       "11   {'max_depth': 50, 'n_estimators': 100}             0.8750   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0              0.8125             0.9375             1.0000   \n",
       "16             0.8125             0.8125             0.9375   \n",
       "4              0.8750             0.8750             0.8750   \n",
       "8              0.8125             0.8750             1.0000   \n",
       "11             0.8750             0.8125             1.0000   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.933333         0.924167        0.061090                1  \n",
       "16           0.933333         0.886667        0.060576                2  \n",
       "4            0.933333         0.886667        0.023333                2  \n",
       "8            0.866667         0.885833        0.061667                4  \n",
       "11           0.866667         0.885833        0.061667                4  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_rf_fit.cv_results_).sort_values(\"mean_test_score\", ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
